package cs.Lab2.WordCount;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class DerniereTache {

    public static void main (String[] args) throws Exception {

    	
    	Configuration conf = new Configuration();

        // Création d'un job en lui fournissant la configuration et une description textuelle de la tâche

        Job job = Job.getInstance(conf, " test compteur de mots");
        // On précise les classes MyProgram, Map et Reduce

        job.setJarByClass(DerniereTache.class);

        job.setMapperClass(DerniereTacheMapper.class);

        job.setReducerClass(DerniereTacheReducer.class);


        // Définition des types clé/valeur de notre problème

        job.setMapOutputKeyClass(Text.class);

        job.setMapOutputValueClass(Text.class);

        // Définition des fichiers d'entrée et de sorties (ici considérés comme des arguments à préciser lors de l'exécution)

    //    FileInputFormat.addInputPath(job, new Path("/home/cloudera/anna_karenina.txt"));

        MultipleInputs.addInputPath(job, new Path("/home/cloudera/Data_Lab2/TotalMots.txt"), TextInputFormat.class);

        FileOutputFormat.setOutputPath(job, new Path("/home/cloudera/Data_Lab2/TFIDFResultats.txt"));

        FileSystem fs = FileSystem.newInstance(conf);

        if (fs.exists(new Path("/home/cloudera/Data_Lab2/TFIDFResultats.txt"))) {

            fs.delete(new Path("/home/cloudera/Data_Lab2/TFIDFResultats.txt"), true);

        }

        if(job.waitForCompletion(true))
        	System.exit(0);
        System.exit(-1);
    }


}
